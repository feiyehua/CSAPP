# Optimizing Program Performance
## 5.4 Eliminating Loop Inefficiencies
Remove the call `vec_length` in loop condition. This involves *code motion*, identifying a computation that is performed multiple times without a change in the result.

Sometimes the compiler can do some code motion, but cases like calling `strlen` in loop condition is beyond the most sophisticated compiler's ability.

## 5.5 Reducing Procedure Calls
Remove some unnecessary function calls in the loop.

## 5.6 Eliminating Unneeded Memory References
Use temprary variable in loop to store the result value, and write back in the end of loop.
```c
/* Access dest in loop */
void combine3(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);

    *dest = IDENT;
    for (i = 0; i < length; i++) {
        *dest = *dest OP data[i];
    }
}
```
```c
/* Accumulate result in local variable */
void combine4(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;

    for (i = 0; i < length; i++) {
        acc = acc OP data[i];
    }
    *dest = acc;
}
```
Considering memory aliasing, the codes have different behaviors, so the compiler would not do such optimization.

## 5.8 Loop Unrolling
Loop unrolling may eliminate some potential control computation.

```c
/* 2 x 1 loop unrolling */
void combine5(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    long limit = length - 1;
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;

    /* Combine 2 elements at a time */
    for (i = 0; i < limit; i += 2) {
        acc = (acc OP data[i]) OP data[i+1];
    }

    /* Finish any remaining elements */
    for (; i < length; i++) {
        acc = acc OP data[i];
    }
    *dest = acc;
}
```

This is an example of $2\times 1$ loop unrolling.
Loop unrolling is enabled by default with flag `-O3`.

## 5.9 Enhancing Parallelism
### 5.9.1 Multiple Accumulators

```c
/* 2 x 2 loop unrolling */
void combine6(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    long limit = length - 1;
    data_t *data = get_vec_start(v);
    data_t acc0 = IDENT;
    data_t acc1 = IDENT;

    /* Combine 2 elements at a time */
    for (i = 0; i < limit; i += 2) {
        acc0 = acc0 OP data[i];
        acc1 = acc1 OP data[i+1];
    }

    /* Finish any remaining elements */
    for (; i < length; i++) {
        acc0 = acc0 OP data[i];
    }
    
    *dest = acc0 OP acc1;
}
```

By using $2 \times 2$ loop unrolling and having 2-way parallelism, we can break through the barrier imposed by latency bound by making use of the multiple function units in the processor.

For a $k \times k$ unrolling, if $k$ is sufficiently large, the program can achieve nearly the throughput bounds.

For an operation with latency $L$ and capacity $C$, this requires an unrolling factor $k \geq C \times L$.

### 5.9.2 Reassociation Transformation
Make the following *Reassociation Transformation*:
from
```c
acc = (acc OP data[i]) OP data[i+1];
```
to
```c
acc = acc OP (data[i] OP data[i+1]);
```

This is referred to as $2 \times 1a$ loop unrolling.

![](figures/figure5.20_data_flow_2_times_1_unrolling.png)
![](figures/figure5.29_data_flow_reassociate_tranformation.png)
We still only have 1-way critical path, but only have $\frac{1}{2} \times n$ operators on the critical path.


In summary, by removing operators from the critical path, we can achieve better instruction-level parallelism. The operators out side of critical path can be performed in advance, prior to the actual iteration begins, thanks to the out-of-order feature of modern processors. 